{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GCAM Annual Meeting 2023 Tutorial\n",
    "\n",
    "The purpose of this tutorial is to demonstrate how `stitches` can be used as an emulator. While `stitches` can\n",
    " emulate a number of CMIP6 models, this example will focus on emulating CanESM5 SSP245 results.\n",
    "\n",
    "This tutorial also assumes that the user has either seen a talk on `stitches` or\n",
    "read the paper published in _Earth System Dyanmics_ (Tebaldi et al 2022). This\n",
    "tutorial is aimed at highlighting the flexibility of functions in `stitches`.\n",
    "\n",
    "A simpler quickstart notebook comes in every stitches download:\n",
    "\n",
    "https://github.com/JGCRI/stitches/blob/main/notebooks/stitches-quickstart.ipynb\n",
    "\n",
    "Both notebooks assume a familiarity with CMIP-style data.\n",
    "\n",
    "To use `stitches`, there are a number of decisions users have to make,\n",
    "perhaps the most important being:\n",
    "\n",
    "* Which ESM will `stitches` emulate?\n",
    "* What archive data will be used? These are values that the target data will be matched to. It should only\n",
    "contain data for the specific ESM that is being emulated. Users may limit the number of experiments or\n",
    "ensemble realizations within the archive in order to achieve their specific experimental setup.\n",
    "* What target data will be used? This data frame represents the temperature pathway the stitched product\n",
    "will follow. The contents of this data frame may come from CMIP6 ESM results for an SSP or it may follow\n",
    "some arbitrary pathway.\n",
    "\n",
    "A diagram illustrating the `stitches` process is included for reference:\n",
    "\n",
    "![stitches workflow](figs/stitches_diagram.jpg)\n",
    "\n",
    "- `stitches` defaults to $X=9$ year windows.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, if one were to take smoothed ESM data for many scenarios and plot the\n",
    "global average temperature, the vertical lines drawn here represents a _potential_\n",
    "segmenting of the data into those 9 year windows:\n",
    "\n",
    "![Example Tgav](figs/Tutorial_2023_tgavex.jpg)\n",
    "\n",
    "\n",
    "In each segment, the median temperature value and the change in value per segment\n",
    "can be plotted in a two dimensional space:\n",
    "\n",
    "![Example T, dT](figs/Tutorial_2023_T_dT_example.jpg)\n",
    "\n",
    "The black points represent a 'target' scenario. This two dimensional space is where\n",
    "matching to the available archive points (colorful) occurs.\n",
    "\n",
    "\n",
    "# Getting Started\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import stitches\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the additional python libraries that will be used in this example.\n",
    "These packages are installed as `stitches` dependencies."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pkg_resources\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# For help with plotting\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Install the package data from Zenodo\n",
    "\n",
    "The package data is all data that has been processed from raw Pangeo data\n",
    " and is generated with package functions. For convenience and rapid cloning\n",
    " of the github repository, the package data is also minted on Zenodo and\n",
    " can be quickly downloaded for using the package.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# stitches.install_package_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example Set Up\n",
    "\n",
    "In this example, we will use `stitches` to emulate CanESM5 SSP245 results.\n",
    "Then we will compare the `stitches` results with actual CMIP6 CanESM5 SSP245\n",
    "output data. This is our _Target Data_.\n",
    "\n",
    "For CMIP6 results, Earth system model data runs from 1850-2100 (or 2099,\n",
    "depending on the ESM). This tutorial will focus on emulating that entire period.\n",
    "\n",
    "# Decide on the target data\n",
    "- The primary input to `stitches` functions that most users will adjust is the\n",
    "target data.\n",
    "\n",
    "- The target data is the temperature pathway the stitched (emulated) product\n",
    "will follow. This data can come from an ESM or another class of climate models,\n",
    "for a specific SSP scenario or an arbitrarily defined scenario. Similarly to the archive\n",
    "data, the target data should contain the mean temperature anomaly and rate of\n",
    "temperature change over a window of time.\n",
    "\n",
    "- The target data window and the archive window must be the same length,\n",
    "`stitches` uses a 9-year window by default.  `stitches` includes functions for\n",
    "processing raw ESM  Tgav data into the structure it needs for matching.\n",
    "- In this example, we will use CanESM5 SSP245 results for a single ensemble\n",
    "member to use as our target data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load time series and subset to target time series if needed:\n",
    "data_directory = pkg_resources.resource_filename('stitches', \"data\")\n",
    "targ = pd.read_csv(os.path.join(data_directory, \"tas-data\", \"CanESM5_tas.csv\"))\n",
    "target_data = targ.loc[(targ[\"model\"] == \"CanESM5\")\n",
    "                       & (targ[\"experiment\"] == 'ssp245')].copy()\n",
    "\n",
    "target_data  = target_data[target_data[\"ensemble\"].isin(['r1i1p1f1'])].copy()\n",
    "\n",
    "target_data = target_data.drop(columns='zstore').reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Take a look at the structure and a plot of the time series we will be targeting:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(target_data.head())\n",
    "target_data.plot(x='year', y='value')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Critically, these time series are _global average temperature anomaly from\n",
    "1995-2014 average_.\n",
    "- Note that Hector outputs are in terms of anomaly from pre-industrial average,\n",
    "so Hector outputs will need a shift before being used as targets for stitching.\n",
    "\n",
    "\n",
    "- Any time series of global average temperature anomalies can be used as a\n",
    "target. However, the data frame containing this time series must be structured as\n",
    "above: a `variable` column containing entries of 'tas',  `year` and `value`\n",
    "columns containing the data, and `experiment`, `ensemble`, `model` columns\n",
    "with identifying information of the source of this target data.\n",
    "- The actual entries in the `experiment`, `ensemble`, `model` columns are only\n",
    "used for generating identifying strings for generated ensemble members.\n",
    "\n",
    "\n",
    "- In this demonstration, we will specifically be targeting ensemble member 1\n",
    "of the CanESM5 SSP245 simulations. The entire SSP245 ensemble may be\n",
    "jointly targeted by omitting the line\n",
    "`target_data  = target_data[target_data[\"ensemble\"].isin(['r1i1p1f1'])].copy()`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decide on the archive data\n",
    "\n",
    "- Limit the archive matching data to the model we are trying to emulate, CanESM5\n",
    "in this case.\n",
    "- In this example, we treat SSP245 as a novel scenario rather than one\n",
    "run by the ESM and available, so we exclude it from the archive data.\n",
    "- The internal package data called `matching_archive` contains the temperature\n",
    "results for all the ESMs-Scenarios-ensemble members that are available for\n",
    "`stitches` to use in its matching process. In this file monthly, tas output has\n",
    "been processed to mean temperature anomaly and the temperature change over a\n",
    "window of time. By default `stitches` uses a 9-year window.\n",
    "\n",
    "- `stitches` actually provides two files in its pacakge data.\n",
    "- `matching_archive.csv` can be considered the default (for now). Starting in\n",
    "1850, nine year windows are sliced forward and don't overlap.\n",
    "- The final window ends up beginning in 2093, and is only 8 years long to\n",
    "terminate in 2100 (7 years if the ESM ends in 2099).\n",
    "- When an 8 year archive window gets matched to a 9 year target window,\n",
    "`stitches` repeats the final archive window year to get to 9 years.\n",
    "- For ESMs that end in 2099, the 2093-2099 seven-year window must be omitted\n",
    "\n",
    "- That means that we lose some of the most interesting differences between\n",
    "scenarios.\n",
    "- Therefore, `stitches` includes `matching_archive_staggered.csv` as package\n",
    "data as well. The difference is that this file does every possible full 9-year chunk,\n",
    "not just slicing sequentially from the starting point.\n",
    "- We have to do a little more pre-processing for the archive data, but it offers\n",
    "more flexibility and robustness.\n",
    "- The `stitches_quickstart` notebook that ships with the package uses the\n",
    "default `matching_archive.csv` and is generally a shorter version of this tutorial."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read in the package data of all ESMs-Scenarios-ensemble members avail.\n",
    "data_directory = pkg_resources.resource_filename('stitches', \"data\")\n",
    "path = os.path.join(data_directory, 'matching_archive_staggered.csv')\n",
    "data = pd.read_csv(path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra preprocessing for `matching_archive_staggered.csv`\n",
    "Let's start from the final ESM year, 2100 for CanESM5, and prioritize getting that\n",
    "as a full 9 year window. Short windows can be on the front end.\n",
    "\n",
    "- if the final year for an ESM is 2099, you'd just do\n",
    "`end_yr_vector = end_yr_vector-1` to shift everything up a year.\n",
    "\n",
    "\n",
    "We define a helper function for selecting from `matching_archive_staggered.csv`\n",
    "to create more custom archives. On the `dev` branch, this is a package function\n",
    "under `stitches.fx_processing.subset_archive()`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a helper function for selecting archive years\n",
    "def subset_archive(staggered_archive, end_yr_vector):\n",
    "    \"\"\" Take a staggered archive with chunked data for a 9 year window following\n",
    "         each year in 1850-2100 and subset to the entries with `end_yr` in\n",
    "         `end_yr_vector`.\n",
    "      :param staggered_archive:     A formatted archive with chunked data starting\n",
    "                                                 in each year\n",
    "      :type df:     pandas DataFrame\n",
    "\n",
    "      :param end_yr_vector:   vector of end_yrs want to subset the archive to.\n",
    "\n",
    "\n",
    "      :return:    pandas DataFrame of the subsetted archive, same format just fewer\n",
    "                    entries\n",
    "      \"\"\"\n",
    "\n",
    "    out = staggered_archive[staggered_archive['end_yr'].isin(end_yr_vector)].reset_index(drop=True).copy()\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "staggered_archive = data.copy()\n",
    "\n",
    "end_yr_vector = [1857, 1866, 1875,1884, 1893,\n",
    "                 1902, 1911, 1920, 1929, 1938, 1947,\n",
    "                 1956,  1965, 1974, 1983, 1992, 2001,\n",
    "                 2010, 2019, 2028, 2037, 2046, 2055,\n",
    "                 2064, 2073, 2082, 2091, 2100]\n",
    "\n",
    "tmp = staggered_archive.loc[(data[\"experiment\"].isin(['ssp126', 'ssp370', 'ssp585']))\n",
    "                       & (data[\"model\"] == \"CanESM5\")].copy()\n",
    "archive_data = subset_archive(staggered_archive = tmp,\n",
    "                              end_yr_vector = end_yr_vector)\n",
    "\n",
    "print(archive_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The staggered archive ONLY has 9 year windows, no short windows. So no window\n",
    "from 1850-1857 exists to get pulled for that `end_yr`.\n",
    "The historical period is so consistent, there are plenty of other full sized (9year)\n",
    "windows that have similar properties and can make for a good match, so we aren't\n",
    "really losing anything by not having archive points representing 1850-1857.\n",
    "If we really want, we can go ahead and have an 1850-1858 window in the archive\n",
    "by just replacing 1857 with 1858 in the above. There will be one year (1858) in\n",
    "common between that new window and the one ending in 1866 but that's not\n",
    "an amount of similarity that would lead to unrealistic behavior like if we used\n",
    "all of the entries in the staggered archive.\n",
    "\n",
    "And that would look like:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "end_yr2 = [1858, 1866, 1875,1884, 1893,\n",
    "           1902, 1911, 1920, 1929, 1938, 1947,\n",
    "           1956,  1965, 1974, 1983, 1992, 2001,\n",
    "           2010, 2019, 2028, 2037, 2046, 2055,\n",
    "           2064, 2073, 2082, 2091, 2100]\n",
    "archive_data = subset_archive(staggered_archive = tmp,\n",
    "                              end_yr_vector = end_yr2).sort_values(by=['experiment', 'ensemble', 'end_yr'])\n",
    "print(archive_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is what we will go ahead and use for our archive data.\n",
    "\n",
    "- There is one year of  data (1858) that gets shared between two archive windows.\n",
    "- Therefore it is possible to get a year of data repeated in the stitched outputs.\n",
    "- This is no worse than the default archive, and possibly better to have it happen\n",
    "in the period before the SSPs really diverge.\n",
    "- In general, you don't want many shared years between archive windows, or\n",
    "unrealistic behavior can occur.\n",
    "\n",
    "# Target data pre-processing\n",
    "- We had decided to target SSP245 realization 1 to emulate\n",
    "- Our archive is set up with 9 year chunks, and we prioritized having a full 9 year\n",
    "window ending in 2100 and working backward for that data.\n",
    "- We can do the same thing for our target data.\n",
    "- The target data doesn't necessarily have to have the same length as the\n",
    "archive trajectory.\n",
    "- It does benefit, however, from being a multiple of 9 long, although having an\n",
    "8 year window in the target is fine as well.\n",
    "\n",
    "- Shorter windows in the target are also fine from the perspective of the method,\n",
    "we just haven't coded it cleanly yet.\n",
    "\n",
    "\n",
    "Regardless, the first step of pre-processing any target data is to smooth it.\n",
    "- even Hector outputs, which are already quite smooth, require this."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_data = stitches.fx_processing.calculate_rolling_mean(target_data,\n",
    "                                                            size=31).copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The default chunking, starting with 1850 and cutting every 9 years after that.\n",
    "This results in the final window only being 8 years. That is fine, a target window\n",
    "that is only 1 year short is not a problem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_data1 = stitches.fx_processing.get_chunk_info(\n",
    "    stitches.fx_processing.chunk_ts(df = target_data,  n=9)).copy()\n",
    "print(target_data1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For consistency with how we set up the archive, however, we will have  the target\n",
    "window ending in 2100 be a complete 9 years and work back.\n",
    "\n",
    "You can use the `base_chunk=8` argument to do that. The previous call starting\n",
    "in 1850 and cutting every 9 years aftere that uses the default `base_chunk=0`.\n",
    "`base_chunk=8` means the target starts in 1850+8 = 1858 and cuts every 9\n",
    "years after that, ending in 2100.\n",
    "\n",
    "If the ESM data ends in 2099 and you wanted the target window ending in 2099\n",
    "to be a complete 9 year window, you'd use `base_chunk=7`. It's a little clunky and\n",
    "we could certainly make it more interpretable/flexible, but it's not too bad to\n",
    "figure out for now hopefully."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_data2 = stitches.fx_processing.get_chunk_info(\n",
    "    stitches.fx_processing.chunk_ts(df = target_data,  n=9,\n",
    "                                    base_chunk=8)).copy()\n",
    "print(target_data2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "if you really don't want to sacrifice the 1850-1857 years in the stitched outputs,\n",
    " you can get kind of clunky and play around with the `chunk_ts` arguments to get\n",
    " an 1850-1857 chunk and just append that to the target data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "short_target_window = stitches.fx_processing.get_chunk_info(\n",
    "    stitches.fx_processing.chunk_ts(df = target_data,  n=8,\n",
    "                                    base_chunk=0)).copy()\n",
    "\n",
    "short_target_window = short_target_window[short_target_window['end_yr'] == 1857].copy()\n",
    "\n",
    "print(short_target_window)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_data3 = pd.concat([short_target_window, target_data2]).reset_index(drop=True).copy()\n",
    "print(target_data3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Emulate\n",
    "- now that you are empowered to process almost any data into an archive and a\n",
    "target, we can emulate.\n",
    "\n",
    "- This occurs with two functions:\n",
    "- `stitches.make_recipe()` does the matching between a target and archive,\n",
    "and gives the pointers to all of the pangeo-hosted netcdf files of data.\n",
    "- `stitches.gmat_stitching()` or `stitches.gridded_stitching()` then stitch either\n",
    "global average temperature anomaly  trajectories or gridded, multivariate netcdfs\n",
    "from those recipes.\n",
    "\n",
    "# Matching and making the recipe.\n",
    "The arguments for making recipes are relatively simple. You specify the\n",
    "target data, the archive data, how many matches you want to try to make for\n",
    "each realization of the target data, and whether you want your results to be\n",
    "reproducible.\n",
    "\n",
    "Two other optional variables include\n",
    "- `non_tas_variables` - which variables in addition to tas do you think you want to\n",
    "have gridded results for? The default is to only provide tas recipes.\n",
    "- `res` - do you want to stitch monthly (`'mon'`) or daily (`'day'`) gridded\n",
    "results? The default is to monthly as daily files are very large to work with and\n",
    "create.\n",
    "\n",
    "\n",
    "Within `make_recipe`, two steps are happening:\n",
    " 1. matching - identifying possible archive window matches for each target window\n",
    " 2. permuting - random combinations of those potential matches are drawn to\n",
    "create stitched time series. These draws control for 'envelope collapse', where\n",
    "the same archive window gets used in the same place for many generated\n",
    "ensemble members.\n",
    "\n",
    "The remaining argument, `tol` specifies the matching tolerance - for each target\n",
    "window, how far out away in the archive are we willing to look for similar points?\n",
    "- `stitches` prioritizes providing a nearest neighbor match, which dictates how it\n",
    "currently uses `tol`\n",
    "- `tol=0.0` corresponds to providing the nearest neighbor match.\n",
    "- Each target window gets its own, custom nearest neighbor match that is some\n",
    "distance away, `dist_nn`.\n",
    "- For each target window, we center a circular matching neighborhood on the\n",
    "target point. In a radius of `dist_nn`, we know the nearest neighbor is the only\n",
    "available point by definition.\n",
    "- Therefore, we expand the matching neighborhood for each target point to\n",
    "search for matches up to a distance of `dist_nn + tol` away.\n",
    "- So if target window A has a nearest neighbor 0.1degC away, and `tol=0.01`,\n",
    "then a circle centered on A with radius 0.11degC contains all possible matches.\n",
    "If target window B has a nearest neighbor 0.05degC away, then its matching\n",
    "neighborhood is a circle centered on B with a radius of 0.06degC.\n",
    "\n",
    "\n",
    "- We do this because when doing random draws of all possible combinations of\n",
    "collapse-free ensembles from a set of potential matches, formatting the matching\n",
    "in this way turns finding a cutoff tolerance value for each ESM into a min-max\n",
    "problem that's a little easier to calculate.\n",
    "\n",
    "- In the paper, we provide `z_cutoff` values that are 'safe' maximum tolerances\n",
    "to use for every ESM examined. We will be adding more ESMs in the future."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the nearest neighbor recipes\n",
    "nn_recipes = stitches.make_recipe(target_data = target_data3,\n",
    "                                  archive_data=archive_data,\n",
    "                                  tol=0.0,\n",
    "                                  N_matches=4,\n",
    "                                  reproducible=True)\n",
    "print(nn_recipes.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Depending on the version of stitches being used, you might  get a print statement\n",
    "saying\n",
    "\n",
    "`The following target windows have a nearest neighbor in T, dT space\n",
    "that is more than 0.25degC away. This may or may not result in poor\n",
    "matches and we recommend validation.`\n",
    "\n",
    "This is a flat check we are implementing on our development branch - if any\n",
    "the nearest neighbor matches for any target window are more than 0.25degC\n",
    "away, then this statement is printed with the target window's details.\n",
    "\n",
    "This does not necessarily mean anything is wrong and this flag can be printed in\n",
    "runs that have been validated extremely well.\n",
    "\n",
    "Iit just means that the target trajectory may not be similar enough for the\n",
    "selected archive of data points, and validation is warranted. `stitches` is a\n",
    "constructive method and generally any generated ensemble should be validated\n",
    "against the training data.\n",
    "This is why we pre-calculate the tolerance cutoff values for each ESM in the ESD\n",
    "paper, to save effort validating future generated ensembles."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# additional recipes\n",
    "my_recipes = stitches.make_recipe(target_data = target_data3,\n",
    "                                  archive_data=archive_data,\n",
    "                                  tol=0.05,\n",
    "                                  res='mon',\n",
    "                                   non_tas_variables=['pr'],\n",
    "                                  N_matches=4,\n",
    "                                  reproducible=True)\n",
    "print(my_recipes.head())\n",
    "print('-----------------------------------')\n",
    "# you can take a look at one of the actual file addresses to get a sense of\n",
    "# what the Pangeo file addresses look like.:\n",
    "print(my_recipes['pr_file'].iloc[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you wanted to include sea level pressure in addition to precipitation, you would use\n",
    "`non_tas_variables=['pr', 'psl']`.\n",
    "\n",
    "\n",
    "# stitching and plotting\n",
    "\n",
    "## Nearest neighbor result\n",
    "Stitch the global average temperature for the nearest neighbor result,\n",
    "and see it in the context of the actual ESM data that was not used in the archive\n",
    "at all."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stitched_global_temp = stitches.gmat_stitching(nn_recipes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### nearest neighbor stitched realization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "groups = stitched_global_temp.groupby('stitching_id')\n",
    "\n",
    "for name, group in groups:\n",
    "    plt.plot(group.year, group.value, label = name)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.title(\"Stitched Global Mean Temperature\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# Load the comparison GSAT data\n",
    "data_directory = pkg_resources.resource_filename(\"stitches\", \"data\")\n",
    "data_path = os.path.join(data_directory, \"tas-data\", \"CanESM5_tas.csv\")\n",
    "\n",
    "comp_data = pd.read_csv(data_path)\n",
    "comp_data = comp_data.loc[comp_data[\"experiment\"] == \"ssp245\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### stitched realization and the target ensemble member"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "groups = comp_data.groupby('ensemble')\n",
    "for name, group in groups:\n",
    "    if(group.ensemble.unique() == 'r1i1p1f1'):\n",
    "        plt.plot(group.year, group.value, color = \"black\", linewidth = 2.0)\n",
    "# The stitched realizations:\n",
    "groups = stitched_global_temp.groupby('stitching_id')\n",
    "for name, group in groups:\n",
    "    plt.plot(group.year, group.value, linewidth= 1.0, label = name)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.title(\"Stitched Global Mean Temperature vs CanESM5 Results\")\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### stitched realization and the entire scenario ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# full ensemble of actual ESM runs:\n",
    "groups = comp_data.groupby('ensemble')\n",
    "for name, group in groups:\n",
    "    if(group.ensemble.unique() == 'r1i1p1f1'):\n",
    "        plt.plot(group.year, group.value, color = \"black\", linewidth = 2.0)\n",
    "    else:\n",
    "        plt.plot(group.year, group.value, color = \"0.5\", alpha=0.5)\n",
    "\n",
    "# The stitched realizations:\n",
    "groups = stitched_global_temp.groupby('stitching_id')\n",
    "for name, group in groups:\n",
    "    plt.plot(group.year, group.value, linewidth= 1.0, label = name)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.title(\"Stitched Global Mean Temperature vs CanESM5 Results\")\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# gridded stitching of the non-NN recipes\n",
    "\n",
    "This is a little slow, but it will create the netcdfs according to our stitched recipes\n",
    "that we can load in and work with."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stitches.gridded_stitching(out_dir='.',  rp=my_recipes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "now you have created multiple gridded, monthly tas and pr files that are\n",
    "statistically consistent with the target: SSP245 realization 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "gen_tas = xr.open_dataset('stitched_CanESM5_tas_ssp245~r1i1p1f1~1.nc')\n",
    "gen_tas\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gen_pr = xr.open_dataset('stitched_CanESM5_pr_ssp245~r1i1p1f1~1.nc')\n",
    "gen_pr\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pull comparison netcdfs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fetch the actual data directly from pangeo\n",
    "data_directory = pkg_resources.resource_filename(\"stitches\", \"data\")\n",
    "pangeo_path = os.path.join(data_directory, \"pangeo_table.csv\")\n",
    "\n",
    "pangeo_data = pd.read_csv(pangeo_path)\n",
    "\n",
    "pangeo_data = pangeo_data.loc[(pangeo_data['variable'].isin(['tas', 'pr']))\n",
    "                              & (pangeo_data['domain'].str.contains('mon'))\n",
    "                              & (pangeo_data['experiment'].isin(['ssp245']))\n",
    "                              & (pangeo_data['ensemble'].isin(['r1i1p1f1']))\n",
    "                              & (pangeo_data['model'].isin(['CanESM5']))].copy()\n",
    "\n",
    "# load the target tas netcdf files\n",
    "tas_address = pangeo_data.loc[pangeo_data['variable']== 'tas'].zstore.copy()\n",
    "tar_tas = stitches.fetch_nc(tas_address.values[0])\n",
    "\n",
    "# load the target pr netcdf files\n",
    "pr_address = pangeo_data.loc[pangeo_data['variable']== 'pr'].zstore.copy()\n",
    "tar_pr = stitches.fetch_nc(pr_address.values[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize\n",
    "\n",
    "Select a grid cell and plot the generated and target tas, pr data for first-cut comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define a helper function\n",
    "def plot_comparison(generated_data,\n",
    "                    target_data,\n",
    "                    variable,\n",
    "                    alpha=0.8):\n",
    "    \"\"\"Plot comparision between target variable time series and generated data\"\"\"\n",
    "\n",
    "    if variable.casefold() == \"pr\":\n",
    "        variable_name = \"precipitation\"\n",
    "        units = \"kg m-2 s-1\"\n",
    "    else:\n",
    "        variable_name = \"temperature\"\n",
    "        units = \"C\"\n",
    "\n",
    "    # temperature (tas)\n",
    "    plt.plot(generated_data.time,\n",
    "             generated_data[variable],\n",
    "             label=f\"Generated monthly {variable}\")\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        plt.plot(target_data.indexes['time'].to_datetimeindex(),\n",
    "                 target_data[variable],\n",
    "                 alpha=alpha,\n",
    "                 label = f\"Target monthly {variable}\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(units)\n",
    "    plt.title(f\"Actual and generated monthly {variable_name} ({variable})\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# lon and lat values for a grid cell near the Joint Global Change Research Institute in College Park, MD, USA\n",
    "cp_lat = 38.9897\n",
    "cp_lon = 180 + 76.9378\n",
    "\n",
    "# lat and lon coordinates closest\n",
    "abslat = np.abs(gen_tas.lat - cp_lat)\n",
    "abslon = np.abs(gen_tas.lon-cp_lon)\n",
    "c = np.maximum(abslon, abslat)\n",
    "([lon_loc], [lat_loc]) = np.where(c == np.min(c))\n",
    "lon_grid = gen_tas.lon[lon_loc]\n",
    "lat_grid = gen_tas.lat[lat_loc]\n",
    "\n",
    "cp_tas_gen = gen_tas.sel(lon=lon_grid,\n",
    "                         lat=lat_grid,\n",
    "                         time=slice('2015-01-01', '2099-12-31')).copy()\n",
    "\n",
    "cp_tas_tar = tar_tas.sel(lon=lon_grid,\n",
    "                         lat=lat_grid,\n",
    "                         time=slice('2015-01-01', '2099-12-31')).copy()\n",
    "\n",
    "cp_pr_gen = gen_pr.sel(lon=lon_grid,\n",
    "                       lat=lat_grid,\n",
    "                       time=slice('2015-01-01', '2099-12-31')).copy()\n",
    "\n",
    "cp_pr_tar = tar_pr.sel(lon=lon_grid,\n",
    "                       lat=lat_grid,\n",
    "                       time=slice('2015-01-01', '2099-12-31')).copy()\n",
    "\n",
    "# temperature (tas)\n",
    "plot_comparison(generated_data=cp_tas_gen,\n",
    "                target_data=cp_tas_tar,\n",
    "                variable=\"tas\")\n",
    "\n",
    "# precipitation (pr)\n",
    "plot_comparison(generated_data=cp_pr_gen,\n",
    "                target_data=cp_pr_tar,\n",
    "                variable=\"pr\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visual validation of the complex spatial, temporal, and cross-variable\n",
    "relationships present in ESM outputs is not possible. We extensively validate\n",
    "that the method reproduces ESM internal variability in the ESD paper, but this\n",
    "visual plotting at least suggests that nothing is obviously wrong. In particular,\n",
    "there are no obvious artifacts occurring every 9-years in the generated time\n",
    "series.\n",
    "\n",
    "\n",
    "In other words, it's not inconceivable from these plots that the orange time\n",
    "series were sampled from the same underlying multivariate distribution that\n",
    "generated the blue time series.\n",
    "\n",
    "# Draws of collapse-free generated ensembles\n",
    "\n",
    "As mentioned above, we restrict the generated ensembles of recipes so that they\n",
    "do not undergo envelope collapse.\n",
    "\n",
    "Multiple stochastic draws of such ensembles can, however, be made by turning\n",
    "off the `reproducible` argument.  If these draws of well-behaved ensembles\n",
    "were concatenated into a 'super' ensemble, there WOULD be envelope collapse."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "draw1_recipes = stitches.make_recipe(target_data = target_data3,\n",
    "                                  archive_data=archive_data,\n",
    "                                  tol=0.05,\n",
    "                                  N_matches=4,\n",
    "                                  reproducible=True)\n",
    "\n",
    "draw2_recipes= stitches.make_recipe(target_data = target_data3,\n",
    "                                  archive_data=archive_data,\n",
    "                                  tol=0.05,\n",
    "                                  N_matches=4,\n",
    "                                  reproducible=False)\n",
    "# stitch tgav\n",
    "stitched_global_temp_draw1 = stitches.gmat_stitching(draw1_recipes)\n",
    "stitched_global_temp_draw2 = stitches.gmat_stitching(draw2_recipes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# plot the two well behaved ensembles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "groups = stitched_global_temp_draw1.groupby('stitching_id')\n",
    "\n",
    "for name, group in groups:\n",
    "    plt.plot(group.year, group.value, label = name)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.title(\"Stitched Global Mean Temperature, Draw 1\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "groups = stitched_global_temp_draw2.groupby('stitching_id')\n",
    "\n",
    "for name, group in groups:\n",
    "    plt.plot(group.year, group.value, label = name)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.title(\"Stitched Global Mean Temperature, draw 2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# concatenate to a super-ensemble and plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#update the stitching ids to reflect draws\n",
    "stitched_global_temp_draw1['stitching_id'] = stitched_global_temp_draw1['stitching_id'] + '~draw1'\n",
    "stitched_global_temp_draw2['stitching_id'] = stitched_global_temp_draw2['stitching_id'] + '~draw2'\n",
    "\n",
    "# concatenate\n",
    "super_ensemble = pd.concat([stitched_global_temp_draw1, stitched_global_temp_draw2]).reset_index(drop=True)\n",
    "\n",
    "# plot\n",
    "groups = super_ensemble.groupby('stitching_id')\n",
    "\n",
    "for name, group in groups:\n",
    "    plt.plot(group.year, group.value, label = name)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.title(\"Stitched Global Mean Temperature, super ensemble\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again, around 2075, you can really see that there are not 6 distinct curves, and\n",
    "the same trajectory is being followed for multiple ensemble members.\n",
    "\n",
    "\n",
    "# Bonus example\n",
    "When discussing pre-processing the archive data above, we emphasized not\n",
    "wanting years of ESM data to be included in multiple archive windows.\n",
    "\n",
    "Here, we will use the entire staggered archive, so every year appears in 9 total\n",
    "archive windows. We will just look at the global average temperatures for\n",
    "expediency,\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# All windows for the experiments we want\n",
    "full_staggered_archive = staggered_archive[(staggered_archive['model']== 'CanESM5')&\n",
    "                                           (staggered_archive['experiment'].isin(['ssp126',\n",
    "                                                                                  'ssp370', 'ssp585']))]\n",
    "\n",
    "# make recipes\n",
    "bad_recipes = stitches.make_recipe(target_data = target_data3,\n",
    "                                  archive_data=full_staggered_archive,\n",
    "                                  tol=0.06,\n",
    "                                  N_matches=25,\n",
    "                                  reproducible=True)\n",
    "# stitch tgav\n",
    "stitched_global_temp = stitches.gmat_stitching(bad_recipes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "groups = stitched_global_temp.groupby('stitching_id')\n",
    "\n",
    "for name, group in groups:\n",
    "    plt.plot(group.year, group.value, label = name)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.title(\"Stitched Global Mean Temperature\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's not necessarily easy to see, but if you look closely around 1975, you can see\n",
    "several blue and purple curves that are obviously the same archive window offset\n",
    "from each other  by a year or two. While this 'wave'  is NOT envelope collapse,\n",
    "it's also not especially realistic. Having years only occur in 1-2 archive windows\n",
    "helps prevent this from happening.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bonus 2!\n",
    "What does a fully 'bad' match look like?\n",
    "We can go far past the cutoff tolerance values provided in the paper to see"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_recipes2 = stitches.make_recipe(target_data = target_data3,\n",
    "                                  archive_data=archive_data,\n",
    "                                  tol=0.5,\n",
    "                                  N_matches=4,\n",
    "                                  reproducible=True)\n",
    "# stitch tgav\n",
    "stitched_global_temp = stitches.gmat_stitching(bad_recipes2)\n",
    "\n",
    "# plot\n",
    "groups = stitched_global_temp.groupby('stitching_id')\n",
    "\n",
    "for name, group in groups:\n",
    "    plt.plot(group.year, group.value, label = name)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.title(\"Stitched Global Mean Temperature\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These curves (especially the red curve) are clearly rapidly switching between\n",
    "archive scenarios as they sort of follow the target scenario's mean, rather than\n",
    "matching the target scenario well."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-58c3bd78",
   "language": "python",
   "display_name": "PyCharm (python_curation)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}