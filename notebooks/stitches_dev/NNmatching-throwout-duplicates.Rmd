---
title: "Nearest-neighbor matching: no repeat matches within a match to a single target"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '4'
    toc_float: yes
    number_sections: true
date: "`r format(Sys.time(), '%d %B, %Y')`"
---

# Goal

Rewrite the matching routine so that within a single target trajectory being matched, no two target years get the exact same archive value matched in.

# Set Up 
```{r, message=FALSE, warning=FALSE}
# required packages
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)


# The load the functions we will want to use, these are currently written in R and will be translated into python. 
source("nearest_neighbor_matching.R") # the function match_neighborhood is defined here
source("stitching_functions.R")  # the function stitch_global_mean is definend here 
```


Load the inputs. 

```{r}
# Time series of the raw global mean temperature anomaly, this is the data that is 
# going to be stitched together. Historical data is pasted into every scenario. No
# smoothing has been done.
tgav_data <- read.csv("inputs/main_raw_pasted_tgav_anomaly_all_pangeo_list_models.csv", 
                      stringsAsFactors = FALSE) %>% dplyr::select(-X)


# A chunked smoothed tgav anomaly archive of data. This was tgav_data but several 
# steps were taken in python to transform it into the "chunked" data and save it 
# so that we do not have to repeate this process so many times. 
archive_data <- read.csv('inputs/archive_data.csv', stringsAsFactors = FALSE)


# This is chunked smooth tgav anomaly for a single model/experiment/ensemble
# member, saved for our convenience. If you decide that you want to work with 
# a different different target data subset you can subset it from the
# archive_data data frame. This file is SSP245 Realization 1.
target_data <- read.csv("inputs/target_data.csv", stringsAsFactors = FALSE)

# For plotting
tgav_data %>%  
  filter(model == unique(target_data$model) & experiment == unique(target_data$experiment) & 
           ensemble == unique(target_data$ensemble)) -> 
  original_data1

# target data 2: ssp245 realization 4
archive_data %>%
  filter(experiment == 'ssp245' & ensemble == 'r4i1p1f1') ->
  target_data2
```


# Subset of archive for testing


```{r}
# data that will for sure have the same value getting matched in multiple times
archive_data %>% 
  dplyr::filter(model == unique(target_data$model)) %>%  
  dplyr::filter(experiment == 'ssp126' | experiment == 'ssp585') %>%
  filter(ensemble == 'r1i1p1f1' | ensemble == 'r2i1p1f1') ->
  archive_subset
```

# Current matching
```{r}
matched <- match_neighborhood(target_data = target_data, archive_data = archive_subset)
```


We can see duplicates came in because of the limited size of the archive we gave it:
```{r, echo=FALSE}
stitch_global_mean(match = matched, data = tgav_data) %>% 
  mutate(target = "ssp245-realization1-duplicates") -> 
  out1a

ggplot() + 
  geom_line(data = original_data1, aes(year, value), color = "grey") + 
  geom_line(data = out1a, aes(year, value, color = target)) + 
  theme_bw() + 
  labs(title = "Comparison of ESM and Stitched Data",
       x = "Year", y = "Deg C")

```

# Proposed change
As we intended from our choice of archive, this set of matched data has duplicate matches. 

If two target years get the same archive point matched, the archive point stays with the target year with smallest `dist_l2`. The other target year re-matches  the larger `dist_l2` points on a subsetted archive with these duplicate archive points removed.

There's an element of recursion here (via the while loop): we only remove the duplicated match point from the archive when re-matching, we update the matched data with the re-matched points, and we check the entire matched data for duplicates again.
 
```{r}
matched_no_dup <- remove_duplicates(matched)
```



# Compare the Tgav

Did double check that the last two chunks aren't repeats: both archive year 2061 from ssp585 but different realizations and therefore different archive values.

```{r, echo=FALSE}
stitch_global_mean(match = matched_no_dup, data = tgav_data) %>% 
  mutate(target = "ssp245-realization1-noduplicates") -> 
  out1

ggplot() + 
  geom_line(data = original_data1, aes(year, value), color = "grey") + 
  geom_line(data = out1, aes(year, value, color = target)) + 
  geom_line(data = out1a, aes(year, value, color = target)) + 
  theme_bw() + 
  labs(title = "Comparison of ESM and Stitched Data",
       x = "Year", y = "Deg C")
```



# Apply to a less-restricted archive, stitch and plot

```{r}
archive_data %>% 
  dplyr::filter(model == unique(target_data$model)) %>%  
  dplyr::filter(experiment == 'ssp126' | experiment == 'ssp585') ->
  archive_subset

# okay so there is a problem where the duplicates don't work wi
  remove_duplicates(matched_data = match_neighborhood(target_data = target_data, 
                                                      archive_data = archive_subset)) %>% 
  stitch_global_mean(match = ., data = tgav_data) %>% 
  mutate(target = "ssp245-realization1-noduplicates") -> 
  out1

match_neighborhood(target_data = target_data, archive_data = archive_subset) %>%
  stitch_global_mean(match = ., data = tgav_data) %>% 
  mutate(target = "ssp245-realization1-duplicates") -> 
  out1a

ggplot() + 
  geom_line(data = original_data1, aes(year, value), color = "grey") + 
    geom_line(data = out1a, aes(year, value, color = target)) +
  geom_line(data = out1, aes(year, value, color = target)) + 
  theme_bw() + 
  labs(title = "Comparison of ESM and Stitched Data",
       x = "Year", y = "Deg C")

```




